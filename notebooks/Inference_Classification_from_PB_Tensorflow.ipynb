{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.5/dist-packages (3.4.3.18)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.5/dist-packages (from opencv-python) (1.15.2)\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Hit:1 http://archive.ubuntu.com/ubuntu xenial InRelease\n",
      "Hit:2 http://security.ubuntu.com/ubuntu xenial-security InRelease       \u001b[0m\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu xenial-updates InRelease         \u001b[33m\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu xenial-backports InRelease\n",
      "Reading package lists... Done[0m\u001b[33m\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "16 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libsm6 is already the newest version (2:1.2.2-1).\n",
      "libxext6 is already the newest version (2:1.3.3-1).\n",
      "libxrender1 is already the newest version (1:0.9.9-0ubuntu1).\n",
      "libfontconfig1 is already the newest version (2.11.94-0ubuntu1.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 16 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!apt update && apt install -y libsm6 libxext6 libfontconfig1 libxrender1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 1.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PB: the frozen model\n",
    "pb.txt: the label map file\n",
    "\"\"\"\n",
    "PB_NAME = \"ssd_inception_v2_m_0.2.1\"\n",
    "#PATH_TO_PB = \"/Users/jiankaiwang/devops/Fruit_Recognition/models/ssd_inception_v2/res/m200000/{}.pb\".format(PB_NAME)\n",
    "#PATH_TO_LABELS = \"/Users/jiankaiwang/devops/Fruit_Recognition/models/ssd_inception_v2/image_label.pbtxt\"\n",
    "PATH_TO_PB = \"/notebooks/devops/Auxiliary_Operations/model/inception_single_0.1/inception_single_0.1.pb\"\n",
    "PATH_TO_LABELS = \"/notebooks/devops/Auxiliary_Operations/model/inception_single_0.1/inception_single_0.1.txt\"\n",
    "\n",
    "PATH_TO_PICKLE_DIR = \"/notebooks/devops/Auxiliary_Operations/model/inception_single_0.1\"\n",
    "\n",
    "if not os.path.exists(PATH_TO_PB): raise FileNotFoundError(\"PB is not found.\")\n",
    "if not os.path.exists(PATH_TO_LABELS): raise FileNotFoundError(\"Label is not found\")\n",
    "if not os.path.exists(PATH_TO_PICKLE_DIR): raise FileNotFoundError(\"PICKLE PATH is not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load frozen graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_PB, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show all operation names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder:0\n",
      "module/InceptionV3/Conv2d_1a_3x3/weights:0\n",
      "module/InceptionV3/Conv2d_1a_3x3/BatchNorm/beta:0\n",
      "module/InceptionV3/Conv2d_1a_3x3/BatchNorm/moving_mean:0\n",
      "module/InceptionV3/Conv2d_1a_3x3/BatchNorm/moving_variance:0\n",
      "module/InceptionV3/Conv2d_2a_3x3/weights:0\n",
      "module/InceptionV3/Conv2d_2a_3x3/BatchNorm/beta:0\n",
      "module/InceptionV3/Conv2d_2a_3x3/BatchNorm/moving_mean:0\n",
      "module/InceptionV3/Conv2d_2a_3x3/BatchNorm/moving_variance:0\n",
      "module/InceptionV3/Conv2d_2b_3x3/weights:0\n",
      "...\n",
      "module_apply_default/InceptionV3/Logits/GlobalPool:0\n",
      "module_apply_default/hub_output/feature_vector/SpatialSqueeze:0\n",
      "input/BottleneckInputPlaceholder:0\n",
      "final_retrain_ops/weights/final_weights:0\n",
      "final_retrain_ops/weights/final_weights/read:0\n",
      "final_retrain_ops/biases/final_biases:0\n",
      "final_retrain_ops/biases/final_biases/read:0\n",
      "final_retrain_ops/Wx_plus_b/MatMul:0\n",
      "final_retrain_ops/Wx_plus_b/add:0\n",
      "final_result:0\n"
     ]
    }
   ],
   "source": [
    "def show_operation_names(count=10):\n",
    "    with detection_graph.as_default():\n",
    "        with tf.Session() as sess:\n",
    "            opts = tf.get_default_graph().get_operations()\n",
    "            for opt in opts[:count]: \n",
    "                for output in opt.outputs: print(output.name)\n",
    "            print(\"...\")\n",
    "            for opt in opts[-count:]: \n",
    "                for output in opt.outputs: print(output.name)\n",
    "                    \n",
    "show_operation_names(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Label file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(1, 'hole'), (2, 'screw')])\n",
      "OrderedDict([('hole', 1), ('screw', 2)])\n"
     ]
    }
   ],
   "source": [
    "category_index = OrderedDict()\n",
    "name_indx = OrderedDict()\n",
    "count = 1\n",
    "with open(PATH_TO_LABELS, \"r\") as fin:\n",
    "    tmpData = \"\"\n",
    "    for line in fin:\n",
    "        tmpData = line.strip()\n",
    "        category_index[count] = tmpData\n",
    "        name_indx[tmpData] = count\n",
    "        count += 1\n",
    "    print(category_index)\n",
    "    print(name_indx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_single_image(image, graph):\n",
    "    with graph.as_default():\n",
    "        with tf.Session() as sess:\n",
    "            # handle input and output tensor\n",
    "            opts = tf.get_default_graph().get_operations()\n",
    "            all_tensorflow_names = { output.name for opt in opts for output in opt.outputs }\n",
    "            tensor_dict = {}\n",
    "            for key in ['final_result']:\n",
    "                tensor_name = key + ':0'\n",
    "                if tensor_name in all_tensorflow_names:\n",
    "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(tensor_name)\n",
    "                    \n",
    "            # run for single image            \n",
    "            # input\n",
    "            image_tensor = tf.get_default_graph().get_tensor_by_name('Placeholder:0')\n",
    "            \n",
    "            # inference\n",
    "            output_dict = sess.run(tensor_dict, feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "            \n",
    "            # convert data type float32 to appropriate\n",
    "            output_dict['final_result'] = output_dict['final_result']\n",
    "            \n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_image(imagePath):\n",
    "    image_path = imagePath\n",
    "    if not os.path.exists(image_path): raise FileNotFoundError(\"{} not found.\".format(image_path))\n",
    "        \n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (299, 299), interpolation=cv2.INTER_CUBIC)\n",
    "    image_np = image[:,:,::-1]\n",
    "    output_dict = inference_single_image(image_np, detection_graph)\n",
    "    \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'final_result': array([[3.6213717e-06, 9.9999642e-01]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "#image_path = '/Users/jiankaiwang/devops/Fruit_Recognition/eval/qnap_fruit_val_00003.JPEG'\n",
    "image_path = '/notebooks/devops/Auxiliary_Operations/data/IMG_1562_single_crop/screw/IMG_1562_frame_68_597213347968410b3e1b212b7c93a320767da9a1.jpg'\n",
    "output_dict = single_image(image_path)\n",
    "print(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: screw\n"
     ]
    }
   ],
   "source": [
    "cls_idx = int(np.argmax(output_dict['final_result'], axis=1) + 1)\n",
    "print(\"Classification: {}\".format(category_index[cls_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
